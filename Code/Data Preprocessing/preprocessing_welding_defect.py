# -*- coding: utf-8 -*-
"""Preprocessing Welding defect

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1otEx2MDNra0-_qJFxP3I2BKalrV3T1Ms

# Importing libraries
"""

# Commented out IPython magic to ensure Python compatibility.
# Clone YOLOv5 repository
!git clone https://github.com/ultralytics/yolov5
# %cd yolov5

# Install required dependencies
!pip install -r requirements.txt

"""# Unified Model Architecture

Input Image
   → Pretrained YOLO (Feature Extraction + Bounding Box Predictions)
      → ROI Pooling Layer (Extract Features for Each Bounding Box)
         → Classifier Head (Fine-tuned VGG16 or Custom CNN for Defect Classification)
            → Combined Output (Bounding Boxes + Defect Labels)
"""

from google.colab import drive
drive.mount('/content/drive')

!pip install ultralytics tensorflow keras

"""# Loding dataset"""

import zipfile

# Path to the uploaded file
zip_file_path = '/content/train.zip'

# Path to extract the contents
extract_path = '/content/train'

# Unzipping the file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print(f"Files extracted to {extract_path}")

import zipfile

# Path to the uploaded file
zip_file_path = '/content/test.zip'

# Path to extract the contents
extract_path = '/content/test'

# Unzipping the file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print(f"Files extracted to {extract_path}")

import os
import tensorflow as tf

# Dataset loader with robustness
def load_dataset(image_dir, label_dir, target_size=(640, 640)):
    images = []
    bboxes = []
    labels = []
    missing_labels = []
    corrupt_labels = []

    for img_file in os.listdir(image_dir):
        try:
            # Load image
            img_path = os.path.join(image_dir, img_file)
            image = tf.io.read_file(img_path)
            image = tf.image.decode_jpeg(image, channels=3)
            image = tf.image.resize(image, target_size) / 255.0  # Normalize to [0, 1]

            # Load corresponding label
            label_file = os.path.join(label_dir, img_file.replace('.jpg', '.txt'))
            if not os.path.exists(label_file):
                missing_labels.append(img_file)
                continue  # Skip if label file is missing

            with open(label_file, 'r') as f:
                label_data = f.readlines()

            bbox = []
            class_ids = []
            for line in label_data:
                try:
                    # Parse YOLO label format
                    class_id, x_center, y_center, width, height = map(float, line.strip().split())
                    class_ids.append(int(class_id))

                    # Convert YOLO format to [x_min, y_min, x_max, y_max]
                    x_min = (x_center - width / 2) * target_size[0]
                    y_min = (y_center - height / 2) * target_size[1]
                    x_max = (x_center + width / 2) * target_size[0]
                    y_max = (y_center + height / 2) * target_size[1]
                    bbox.append([x_min, y_min, x_max, y_max])
                except ValueError:
                    corrupt_labels.append(label_file)
                    break  # Skip this image if label parsing fails

            if bbox:  # Add only if bounding boxes are valid
                images.append(image)
                bboxes.append(bbox)
                labels.append(class_ids)
        except Exception as e:
            print(f"Error processing file {img_file}: {e}")

    if missing_labels:
        print(f"Missing labels for {len(missing_labels)} images.")
    if corrupt_labels:
        print(f"Corrupt labels in {len(corrupt_labels)} files.")

    return images, bboxes, labels

# Paths to train/test folders
train_image_dir = '/content/drive/MyDrive/Building_Defects/Dataset/train/images'
train_label_dir = '/content/drive/MyDrive/Building_Defects/Dataset/train/labels'
test_image_dir = '/content/drive/MyDrive/Building_Defects/Dataset/test/images'
test_label_dir = '/content/drive/MyDrive/Building_Defects/Dataset/test/labels'

# Load train and test datasets
train_images, train_bboxes, train_labels = load_dataset(train_image_dir, train_label_dir)
test_images, test_bboxes, test_labels = load_dataset(test_image_dir, test_label_dir)

print(f"Loaded {len(train_images)} training images and {len(test_images)} test images.")

import shutil
import os
from sklearn.model_selection import train_test_split

# Paths for train and test datasets
train_images_path = "/content/drive/MyDrive/Building_Defects/train/images"
train_labels_path = "/content/drive/MyDrive/Building_Defects/train/labels"
test_images_path = "/content/drive/MyDrive/Building_Defect/test/images"
test_labels_path = "/content/drive/MyDrive/Building_Defects/test/labels"

combined_images_path = "/content/drive/MyDrive/Building_Defects/Dataset/combined/images"
combined_labels_path = "/content/drive/MyDrive/Building_Defects/Dataset/combined/labels"
"""
# Paths for train and test datasets
train_images_path = "/content/Dataset/train/images"
train_labels_path = "/content/Dataset/train/labels"
test_images_path = "/content/Dataset/test/images"
test_labels_path = "/content/Dataset/test/labels"

combined_images_path = "/content/Dataset/combined/images"
combined_labels_path = "/content/Dataset/combined/labels"
"""

# Create output directories if they don't exist
os.makedirs(train_images_path, exist_ok=True)
os.makedirs(train_labels_path, exist_ok=True)
os.makedirs(test_images_path, exist_ok=True)
os.makedirs(test_labels_path, exist_ok=True)

# Combine all image and label files into one list
all_images = os.listdir(combined_images_path)
all_labels = os.listdir(combined_labels_path)

import os
import shutil

# Define your source and destination paths for train and test datasets
train_images_path = "/content/drive/MyDrive/Building_Defects/Dataset/train/images"
train_labels_path = "/content/drive/MyDrive/Building_Defects/Dataset/train/labels"
test_images_path = "/content/drive/MyDrive/Building_Defects/Dataset/test/images"
test_labels_path = "/content/drive/MyDrive/Building_Defects/Dataset/test/labels"

"""## Preparing Dataset pipeline"""

def create_tf_dataset(images, bboxes, labels, batch_size=32):
    dataset = tf.data.Dataset.from_tensor_slices((images, bboxes, labels))
    dataset = dataset.shuffle(buffer_size=len(images))
    dataset = dataset.batch(batch_size).prefetch(tf.data.AUTOTUNE)
    return dataset

# Create train and test datasets
batch_size = 16
train_dataset = create_tf_dataset(train_images, train_bboxes, train_labels, batch_size)
test_dataset = create_tf_dataset(test_images, test_bboxes, test_labels, batch_size)

def yolo_loss(pred_bboxes, true_bboxes):
    # Replace this with a custom YOLO loss function
    return tf.reduce_mean(tf.square(pred_bboxes - true_bboxes))

def classifier_loss(pred_labels, true_labels):
    return tf.keras.losses.SparseCategoricalCrossentropy(from_logits=True)(true_labels, pred_labels)

def combined_loss(bbox_loss, label_loss, alpha=1.0, beta=1.0):
    return alpha * bbox_loss + beta * label_loss

"""# Define the YOLO + Classifier Model"""

import tensorflow as tf
from ultralytics import YOLO
from tensorflow.keras import Model
from tensorflow.keras.layers import Dense, Flatten, GlobalAveragePooling2D

# Load pretrained YOLO model
yolo_model = YOLO('yolov5s.pt')  # Pretrained YOLOv8 weights

def yolo_backbone(image):
    """
    Use YOLO as a feature extractor and bounding box predictor.
    """
    results = yolo_model(image)  # Forward pass through YOLO
    bboxes = results[0].boxes.xyxy  # Extract bounding boxes
    features = results[0].features  # Feature map from YOLO
    return features, bboxes

# Define the Classifier Head (e.g., VGG16 or Custom CNN)
def build_classifier(input_shape=(7, 7, 512), num_classes=4):
    """
    Build the classifier head for defect classification.
    """
    base_model = tf.keras.applications.VGG16(
        weights='imagenet', include_top=False, input_shape=input_shape
    )
    x = base_model.output
    x = GlobalAveragePooling2D()(x)  # Global pooling for feature reduction
    x = Dense(256, activation='relu')(x)  # Fully connected layer
    output = Dense(num_classes, activation='softmax')(x)  # Output layer
    return Model(inputs=base_model.input, outputs=output)

# Build the Unified Model
class YOLOWithClassifier(tf.keras.Model):
    def __init__(self, num_classes):
        super(YOLOWithClassifier, self).__init__()
        self.yolo = yolo_model
        self.classifier = build_classifier(num_classes=num_classes)

    def call(self, inputs):
        # YOLO for feature extraction and bounding box prediction
        features, bboxes = yolo_backbone(inputs)

        # ROI pooling: Use bounding boxes to extract features
        rois = self.roi_pooling(features, bboxes)

        # Classification head
        predictions = self.classifier(rois)

        return bboxes, predictions

    def roi_pooling(self, features, bboxes):
        """
        ROI pooling implementation for extracting bounding box features.
        """
        pooled_features = []
        for bbox in bboxes:
            x1, y1, x2, y2 = map(int, bbox)
            roi = features[:, y1:y2, x1:x2, :]  # Crop the ROI
            roi = tf.image.resize(roi, (7, 7))  # Resize to match classifier input
            pooled_features.append(roi)
        return tf.stack(pooled_features)

def yolo_loss(pred_bboxes, true_bboxes):
    """
    Compute YOLO bounding box loss (e.g., MSE for regression).
    """
    return tf.reduce_mean(tf.square(pred_bboxes - true_bboxes))

def classifier_loss(pred_labels, true_labels):
    """
    Compute classification loss (e.g., Categorical Crossentropy).
    """
    return tf.keras.losses.categorical_crossentropy(true_labels, pred_labels)

def combined_loss(yolo_loss_value, classifier_loss_value, alpha=1.0, beta=1.0):
    """
    Combine YOLO and classifier loss with weights alpha and beta.
    """
    return alpha * yolo_loss_value + beta * classifier_loss_value

# Paths
# Define your pathsPorosity Overweld
categories = [ 'Porosity','Overweld','Underfilled', 'Undercut']
label_map = {0: 'Porosity', 1: 'Overweld', 2: 'Underfilled', 3: 'Undercut'}

import zipfile

# Path to the uploaded file
zip_file_path = '/content/drive/MyDrive/Dataset-20250102T092628Z-001.zip'

# Path to extract the contents
extract_path = '/content'

# Unzipping the file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print(f"Files extracted to {extract_path}")



import zipfile

# Path to the uploaded file
zip_file_path = '/content/test.zip'

# Path to extract the contents
extract_path = '/content/test'

# Unzipping the file
with zipfile.ZipFile(zip_file_path, 'r') as zip_ref:
    zip_ref.extractall(extract_path)

print(f"Files extracted to {extract_path}")

"""
# Now you can download the zip files
from google.colab import files
files.download('/content/augmented_images_labels.zip')
files.download('/content/augmented_labels.zip')"""

import cv2
import os
import albumentations as A

# Paths
input_images_path = "/content/drive/MyDrive/Defects_welding/yolo/original/images"
input_labels_path = "/content/drive/MyDrive/Defects_welding/yolo/original/labels"
output_images_path = "/content/drive/MyDrive/Defects_welding/yolo/Agu/images"
output_labels_path = "/content/drive/MyDrive/Defects_welding/yolo/Agu/labels"

# Create output directories if they don't exist
os.makedirs(output_images_path, exist_ok=True)
os.makedirs(output_labels_path, exist_ok=True)

# Augmentation pipeline
transform = A.Compose(
    [
        A.HorizontalFlip(p=0.5),
        A.VerticalFlip(p=0.3),
        A.Rotate(limit=15, p=0.4),
        A.RandomBrightnessContrast(p=0.4),
    ],
    bbox_params=A.BboxParams(format="yolo", label_fields=["class_labels"]),
)

# Target number of images for each category
target_images_per_category = {
    0: 500,  # overweld
    1: 500,  # porosity
    2: 500,  # undercut
    3: 500,  # underfilled
}

# List all image files in the images folder
image_files = [f for f in os.listdir(input_images_path) if f.endswith('.jpg')]

# Function to get the category of an image from its label file
def get_category_from_label(label_path):
    with open(label_path, "r") as f:
        class_id = int(f.readline().split()[0])  # First entry in label corresponds to the class
    return class_id

# Organize images by category
images_by_category = {0: [], 1: [], 2: [], 3: []}
for img_file in image_files:
    img_path = os.path.join(input_images_path, img_file)
    label_path = os.path.join(input_labels_path, img_file.replace(".jpg", ".txt"))

    # Get the category for the image
    category = get_category_from_label(label_path)

    # Add the image to the appropriate category list
    images_by_category[category].append(img_file)

# Process each category and augment images to meet the target
for category, image_list in images_by_category.items():
    category_name = categories[category]
    current_image_count = len(image_list)
    target_count = target_images_per_category[category]
    augmentations_needed = target_count - current_image_count

    print(f"Processing category: {category_name} | Current: {current_image_count}, Target: {target_count}, Needed: {augmentations_needed}")

    if augmentations_needed > 0:
        for img_file in image_list:
            img_path = os.path.join(input_images_path, img_file)
            image = cv2.imread(img_path)

            label_path = os.path.join(input_labels_path, img_file.replace(".jpg", ".txt"))
            with open(label_path, "r") as f:
                bboxes = []
                class_labels = []
                for line in f.readlines():
                    parts = line.strip().split()
                    class_id = int(parts[0])
                    x_center, y_center, width, height = map(float, parts[1:])
                    bboxes.append([x_center, y_center, width, height])
                    class_labels.append(class_id)

            # Generate the required number of augmentations
            for i in range(augmentations_needed):
                augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)
                augmented_image = augmented["image"]
                augmented_bboxes = augmented["bboxes"]

                # Save augmented image
                aug_img_name = f"aug_{category}_{i}_{img_file}"
                cv2.imwrite(os.path.join(output_images_path, aug_img_name), augmented_image)

                # Save augmented labels
                aug_label_name = f"aug_{category}_{i}_{img_file.replace('.jpg', '.txt')}"
                with open(os.path.join(output_labels_path, aug_label_name), "w") as f:
                    for bbox, class_id in zip(augmented_bboxes, class_labels):
                        f.write(f"{class_id} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\n")

                augmentations_needed -= 1
                if augmentations_needed == 0:
                    break
    else:
        print(f"Category '{category_name}' already meets or exceeds the target count. No augmentation needed.")

print("Augmentation completed!")

import cv2
import os
import albumentations as A
from matplotlib import pyplot as plt
categories = ['Porosity','Overweld', 'Underfilled', 'Undercut']
label_map = {0: 'Porosity', 1: 'Overweld', 2: 'Underfilled', 3: 'Undercut'}
# Paths
input_images_path = "/content/drive/MyDrive/Defects_welding/yolo/original/images"
input_labels_path = "/content/drive/MyDrive/Defects_welding/yolo/original/labels"
output_images_path = "/content/drive/MyDrive/Defects_welding/yolo/Testdata/images"
output_labels_path = "/content/drive/MyDrive/Defects_welding/yolo/Testdata/labels"

# Create output directories if they don't exist
os.makedirs(output_images_path, exist_ok=True)
os.makedirs(output_labels_path, exist_ok=True)

# Augmentation pipeline
transform = A.Compose(
    [

        # **Additional Augmentations**
        A.GaussNoise(var_limit=(10.0, 50.0), p=0.3),  # Add Gaussian noise
        A.MotionBlur(blur_limit=5, p=0.3),  # Apply motion blur  # Random affine transformations
        A.CLAHE(clip_limit=4.0, tile_grid_size=(8, 8), p=0.3),  # Contrast Limited Adaptive Histogram Equalization
        A.ToGray(p=0.2),  # Convert image to grayscale with probability  # Simulate occlusions
    ],
    bbox_params=A.BboxParams(format="yolo", label_fields=["class_labels"]),
)

# Target number of images for each category
target_images_per_category = {
    0: 100,  # overweld
    1: 100,  # porosity
    2: 100,  # undercut
    3: 100,  # underfilled
}

# List all image files in the images folder
image_files = [f for f in os.listdir(input_images_path) if f.endswith('.jpg')]

# Function to get the category of an image from its label file
def get_category_from_label(label_path):
    with open(label_path, "r") as f:
        class_id = int(f.readline().split()[0])  # First entry in label corresponds to the class
    return class_id

# Organize images by category
images_by_category = {0: [], 1: [], 2: [], 3: []}
for img_file in image_files:
    img_path = os.path.join(input_images_path, img_file)
    label_path = os.path.join(input_labels_path, img_file.replace(".jpg", ".txt"))

    # Get the category for the image
    category = get_category_from_label(label_path)

    # Add the image to the appropriate category list
    images_by_category[category].append(img_file)

# Process each category and augment images to meet the target
for category, image_list in images_by_category.items():
    category_name = categories[category]
    current_image_count = 0  # chaned code
    target_count = target_images_per_category[category]
    augmentations_needed = target_count - current_image_count

    print(f"Processing category: {category_name} | Current: {current_image_count}, Target: {target_count}, Needed: {augmentations_needed}")

    if augmentations_needed > 0:
        for img_file in image_list:
            img_path = os.path.join(input_images_path, img_file)
            image = cv2.imread(img_path)

            label_path = os.path.join(input_labels_path, img_file.replace(".jpg", ".txt"))
            with open(label_path, "r") as f:
                bboxes = []
                class_labels = []
                for line in f.readlines():
                    parts = line.strip().split()
                    class_id = int(parts[0])
                    x_center, y_center, width, height = map(float, parts[1:])
                    bboxes.append([x_center, y_center, width, height])
                    class_labels.append(class_id)

            # Generate the required number of augmentations
            for i in range(augmentations_needed):
                augmented = transform(image=image, bboxes=bboxes, class_labels=class_labels)
                augmented_image = augmented["image"]
                augmented_bboxes = augmented["bboxes"]

                # Save augmented image
                aug_img_name = f"aug_{category}_{i}_{img_file}"
                cv2.imwrite(os.path.join(output_images_path, aug_img_name), augmented_image)

                # Save augmented labels
                aug_label_name = f"aug_{category}_{i}_{img_file.replace('.jpg', '.txt')}"
                with open(os.path.join(output_labels_path, aug_label_name), "w") as f:
                    for bbox, class_id in zip(augmented_bboxes, class_labels):
                        f.write(f"{class_id} {bbox[0]} {bbox[1]} {bbox[2]} {bbox[3]}\n")

                augmentations_needed -= 1
                if augmentations_needed == 0:
                    break
    else:
        print(f"Category '{category_name}' already meets or exceeds the target count. No augmentation needed.")

print("Augmentation completed!")

# Function to count images in each category
def count_images_by_category(images_by_category, input_labels_path):
    category_counts = {0: 0, 1: 0, 2: 0, 3: 0}
    for category, image_list in images_by_category.items():
        category_counts[category] = len(image_list)
    return category_counts

# Print initial counts
initial_counts = count_images_by_category(images_by_category, input_labels_path)
print("Initial Counts Per Category:")
for category, count in initial_counts.items():
    print(f"Category {categories[category]} ({category}): {count} images")

# Augmentation process (no changes to previous code here)

# Count images again after augmentation
final_images_by_category = {0: [], 1: [], 2: [], 3: []}
output_image_files = [f for f in os.listdir(output_images_path) if f.endswith('.jpg')]

for img_file in output_image_files:
    label_path = os.path.join(output_labels_path, img_file.replace(".jpg", ".txt"))
    category = get_category_from_label(label_path)
    final_images_by_category[category].append(img_file)

final_counts = count_images_by_category(final_images_by_category, output_labels_path)
print("\nFinal Counts Per Category After Augmentation:")
for category, count in final_counts.items():
    print(f"Category {categories[category]} ({category}): {count} images")

# Function to count total images in all categories
def count_total_images(category_counts):
    return sum(category_counts.values())

# Print initial counts
initial_counts = count_images_by_category(images_by_category, input_labels_path)
initial_total = count_total_images(initial_counts)

print("Initial Counts Per Category:")
for category, count in initial_counts.items():
    print(f"Category {categories[category]} ({category}): {count} images")
print(f"Total images before augmentation: {initial_total}")

# Augmentation process (no changes to previous code here)

# Count images again after augmentation
final_images_by_category = {0: [], 1: [], 2: [], 3: []}
output_image_files = [f for f in os.listdir(output_images_path) if f.endswith('.jpg')]

for img_file in output_image_files:
    label_path = os.path.join(output_labels_path, img_file.replace(".jpg", ".txt"))
    category = get_category_from_label(label_path)
    final_images_by_category[category].append(img_file)

final_counts = count_images_by_category(final_images_by_category, output_labels_path)
final_total = count_total_images(final_counts)

print("\nFinal Counts Per Category After Augmentation:")
for category, count in final_counts.items():
    print(f"Category {categories[category]} ({category}): {count} images")
print(f"Total images after augmentation: {final_total}")

import os
import shutil
original_images_path = "/content/drive/MyDrive/Defects_welding/yolo/original/images"
original_labels_path = "/content/drive/MyDrive/Defects_welding/yolo/original/labels"
augmented_images_path = "/content/drive/MyDrive/Defects_welding/yolo/Agu/images"
augmented_labels_path = "/content/drive/MyDrive/Defects_welding/yolo/Agu/labels"
"""
original_images_path =  "/content/drive/MyDrive/Building_Defects/Dataset/images"
original_labels_path = "/content/drive/MyDrive/Building_Defects/Dataset/labels"
augmented_images_path = "/content/drive/MyDrive/Building_Defects/Dataset/Aaugment_images"
augmented_labels_path = "/content/drive/MyDrive/Building_Defects/Dataset/Aaugmented_labels"
"""
combined_images_path = "/content/drive/MyDrive/Defects_welding/yolo/combined/images"
combined_labels_path = "/content/drive/MyDrive/Defects_welding/yolo/combined/labels"

# Create output directories if they don't exist
os.makedirs(combined_images_path, exist_ok=True)
os.makedirs(combined_labels_path, exist_ok=True)

# Function to copy images and labels to the combined folder with a label (original/augmented)
def copy_images_and_labels(images_path, labels_path, destination_images_path, destination_labels_path, label_type):
    image_files = [f for f in os.listdir(images_path) if f.endswith('.jpg')]  # Adjust image extension if needed

    for image_file in image_files:
        # Copy image file to destination
        src_image_path = os.path.join(images_path, image_file)
        dst_image_path = os.path.join(destination_images_path, f"{label_type}_{image_file}")
        shutil.copy(src_image_path, dst_image_path)

        # Copy corresponding label file to destination
        label_file = image_file.replace(".jpg", ".txt")  # Assuming .txt for label files
        src_label_path = os.path.join(labels_path, label_file)
        dst_label_path = os.path.join(destination_labels_path, f"{label_type}_{label_file}")
        shutil.copy(src_label_path, dst_label_path)

# Copy original images and labels with "original" label
copy_images_and_labels(original_images_path, original_labels_path, combined_images_path, combined_labels_path, "original")

# Copy augmented images and labels with "augmented" label
copy_images_and_labels(augmented_images_path, augmented_labels_path, combined_images_path, combined_labels_path, "augmented")

# Print the number of combined images
combined_image_files = [f for f in os.listdir(combined_images_path) if f.endswith('.jpg')]
print(f"Total images in the combined folder: {len(combined_image_files)}")

# Function to calculate the combined total of original and augmented images
def calculate_totals(images_by_category, augmented_labels_path):
    # Initialize a dictionary to store totals for each category
    combined_counts = {0: 0, 1: 0, 2: 0, 3: 0}

    # Count original images
    for category, files in images_by_category.items():
        combined_counts[category] += len(files)

    # Count augmented images
    augmented_label_files = [f for f in os.listdir(augmented_labels_path) if f.endswith('.txt')]
    for label_file in augmented_label_files:
        label_path = os.path.join(augmented_labels_path, label_file)
        category = get_category_from_label(label_path)
        combined_counts[category] += 1  # Add 1 for each augmented label in the category

    return combined_counts

# Calculate combined totals
combined_counts = calculate_totals(images_by_category, output_labels_path)

# Display combined totals and grand total
print("Combined (Original + Augmented) Counts Per Category:")
grand_total = 0
for category, count in combined_counts.items():
    print(f"Category {categories[category]} ({category}): {count} images")
    grand_total += count

print(f"Grand Total (All Categories): {grand_total} images")

import os
import shutil
from sklearn.model_selection import train_test_split

# Define paths
combined_images_path = "/content/drive/MyDrive/Defects_welding/yolo/combined/images"
combined_labels_path = "/content/drive/MyDrive/Defects_welding/yolo/combined/labels"

train_images_path = "/content/drive/MyDrive/Defects_welding/yolo/train/images"
train_labels_path = "/content/drive/MyDrive/Defects_welding/yolo/train/labels"
test_images_path = "/content/drive/MyDrive/Defects_welding/yolo/test/images"
test_labels_path = "/content/drive/MyDrive/Defects_welding/yolo/test/labels"

# Ensure destination directories exist
os.makedirs(train_images_path, exist_ok=True)
os.makedirs(train_labels_path, exist_ok=True)
os.makedirs(test_images_path, exist_ok=True)
os.makedirs(test_labels_path, exist_ok=True)

# Get list of image and label files
image_files = sorted(os.listdir(combined_images_path))
label_files = sorted(os.listdir(combined_labels_path))

# Ensure each image has a corresponding label
image_files = [img for img in image_files if os.path.splitext(img)[0] + ".txt" in label_files]
label_files = [lbl for lbl in label_files if os.path.splitext(lbl)[0] + ".jpg" in image_files]

# Perform an 80-20 split
train_images, test_images, train_labels, test_labels = train_test_split(
    image_files, label_files, test_size=0.2, random_state=42
)

# Function to move files
def move_files(file_list, source_folder, destination_folder):
    for file_name in file_list:
        shutil.copy(os.path.join(source_folder, file_name), os.path.join(destination_folder, file_name))

# Move training data
move_files(train_images, combined_images_path, train_images_path)
move_files(train_labels, combined_labels_path, train_labels_path)

# Move testing data
move_files(test_images, combined_images_path, test_images_path)
move_files(test_labels, combined_labels_path, test_labels_path)

print("Dataset successfully split and saved!")



